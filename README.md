高可用高并发架构
=========
## 说明
     高可用高并发架构学习，源码和实现可参考我的另一个项目，https://github.com/xingweixiang/SpringCloud
## 目录
* [高可用高并发架构](#高可用高并发架构)
	* [一、高可用](#一高可用)
		* [1、负载均衡与反向代理Nginx](#1负载均衡与反向代理Nginx)
		* [2、隔离术Hystrix](#2隔离术Hystrix)
		* [3、限流](#3限流)
		* [4、降级](#4降级)
		* [5、超时与重试Ribbon](#5超时与重试Ribbon)
		* [6、回滚](#6回滚)
		* [7、压测预案](#7压测预案)
	* [二、高并发](#二高并发)
		* [1、缓存](#1缓存)	
		* [2、连接池线程池](#2连接池线程池)
		* [3、异步并发](#3异步并发)
		* [4、扩容](#4扩容)
		* [5、队列](#5队列)
	
### 一、高可用
### 1、负载均衡与反向代理Nginx
- 负载均衡的作用<br>
1）、转发功能：按照一定的算法【权重、轮询】，将客户端请求转发到不同应用服务器上，减轻单个服务器压力，提高系统并发量。<br>
2）、故障移除：通过心跳检测的方式，判断应用服务器当前是否可以正常工作，如果服务器期宕掉，自动将请求发送到其他应用服务器。<br>
3）、恢复添加：如检测到发生故障的应用服务器恢复工作，自动将其添加到处理用户请求队伍中。<br>
- 外网DNS应该用来实现用GSLB（全局负载均衡）进行流量调度，如将用户分配到离他最近的服务器上以提升体验
- 对于内网DNS，可以实现简单的轮询负载均衡，但会有一定的缓存时间并且没有失败重试机制，我们可以考虑选择如HaProxy和Nginx
- Nginx提供了HTTP（ngx_http_upstreamm_module）七层负载均衡，TCP（ngx_stream_upstream_module）四层负载均衡<br>
A.upstream配置：<br>
1.在http指令下配置upstream即可<br>
2.主要配置：<br>
IP地址和端口<br>
权重：默认是1，越高分配给这台服务器的请求就越多<br>
B.负载均衡算法<br>
1.用来解决用户请求到来时如何选择upstream server进行处理，默认采用的是round-robin(轮询)，同时支持ip_hash<br>
2.hash key [consistent]，对某个key进行哈希或者使用一致性哈希算法进行负载均衡，建议考虑使用一致性哈希算法<br>
3.least_conn，将请求均衡到最少活跃连接的上游服务器<br>
C.失败重试<br>
1.主要两部分配置：<br>
upstream server：server xxxx:80 max_fails=2  fail_timeout=10s weight=1;...
proxy_pass：配置proxy_next_upstream相关配置，proxy_next_upstream、proxy_next_upstream_timeout、proxy_next_upstream_tries
D.健康检查<br>
1.nginx对上游服务器的健康检查默认采用的是惰性策略<br>
2.TCP心跳检查：check interval=3000 rise=1 fall=3 timeout=2000 type=tcp;<br>
3.HTTP心跳检查：<br>
check_http_send "HEAD /status HTTP/1.0\r\n\r\n";
check_http_expect_alive http_2xx http_3xx;
3.使用的是opensresty模块，安装nginx之前需要先打nginx_upstream_check_module补丁<br>
E.其他配置<br>
1.备份上游服务器，backup<br>
2.不可用上游服务器，down<br>
F.长连接<br>
1.可以通过keepalive指令配置长连接数量<br>
- HTTP反向代理<br>
1.反向代理除了实现负载均衡之外，还提供如缓存来减少上游服务器的压力<br>
2.还可以开启gzip压缩，减少网络传输的数据包大小<br>
- HTTP动态负载均衡<br>
1.Consul是一款开源的分布式服务注册与发瑞系统，通过HTTP API可以使得服务注册、发现实现起来非常简单<br>
- Nginx静态负载均衡<br>
启用ngx_stream_core_module，安装Nginx时，添加--with-stream<br>
配置在stream指令下<br>
可配置数据库连接<br>
- Nginx动态负载均衡<br>
nginx-upsync-module，提升了HTTP七层动态负载均衡，动态更新上游服务器不需要reload nginx
### 2、隔离术Hystrix
- 隔离是指将系统或资源分割开，系统隔离是为了在系统发生故障时，能限定传播范围和影响范围，即发生故障后不会出现滚雪球效应，从而保证只有出问题的服务不可用，其他服务还是可用的 
- 资源隔离通过隔离来减少资源竞争，保障服务间的相互不影响和可用性<br>
A.线程隔离<br>
1.主要是指线程池隔离，在实际使用时，我们会把请求分类，然后交给不同的线程池处理<br>
B.进程隔离<br>
1.在公司发展初期，一般是先从零到一，不会一上来就进行系统拆分，这样就会开发出一些大而全的系统，系统中的一个模块/功能出现问题，整个系统就不可用了<br>
2.通过将系统拆分为多个子系统来实现物理隔离，通过进程隔离使得某一个子系统出现问题时不会影响到其他子系统<br>
C.集群隔离<br>
1.随着系统的发展，单实例服务无法满足需求，此时需要服务化技术，通过部署多个服务形成服务集群，来提升系统容量<br>
D.机房隔离<br>
1.随着对系统可用性的要求，会进行多机房部署，每个机房的服务都有自己的服务分组，本机房的服务应该只调用本机房服务，不进行跨机房调用<br>
2.当一个机房服务发生问题时，可以通过DNS/负载均衡将请求全部切到另一个机房，或者考虑服务能自动重试其他机房的服务<br>
3.一种办法是根据IP（不同机房IP段不一样）自动分组，还有一种较灵活的办是通过在分组名中加上机房名<br>
E.读写隔离<br>
1.通过主从模式将读和写集群分离<br>
F.动静隔离<br>
1.将动态内容和静态资源分离，将静态资源放在CDN上<br>
G.爬虫隔离<br>
1.爬虫和正常流量的比例能达到5:1，甚至更高，一种解决办法是通过限流解决，另一种解决办法是在负载均衡层面将爬虫路由到单独集群，Nginx即可配置<br>
2.使用OpenResty，不仅对爬虫user-agent过滤，还会过滤一些恶意IP ，可以考虑IP+Cookie的方式<br>
H.资源隔离<br>
1.最常见的资源，如磁盘、CPU、网络，这些宝贵的资源，都会存在竞争问题<br>
I.使用Hystrix实现隔离<br>
1.Hystrix是Netflix开源的一款针对分布式系统的延迟和容错库，目的是用来隔离分布式服务故障<br>
2.提供线程和信号量隔离，以减少不同服务之间资源竞争带来的相互影响：提供优雅降级机制；提供熔断机制使得服务可以快速失败，而不是一直阻塞等待服务响应，并能从中快速恢复<br>
3.解决的问题：<br>
限制调用分布式服务的资源使用，某一个调用的服务出现问题不会影响其他服务调用，通过线程池隔离和信号量隔离实现<br>
提供了优雅降级机制：超时降级、资源不足时（线程或信号量）降级，降级后可以配合降级接口返回拖底数据<br>
提供了熔断器实现，当失败率达到阈值自动触发降级（如因网络故障/超时造成的失败率高），熔断器触发的快速失败会进行快速恢复<br>
提供了请求缓存、请求合并实现<br>
J.基于Servlet3实现请求隔离<br>
### 3、限流
- 限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据）
- 在压测时我们能找出每个系统的处理峰值，然后通过设定峰值阈值，来防止系统过载时，通过拒绝处理过载的请求来保障系统可用，另外，也应根据系统的吞吐量、响应时间、可用率来动态调整限流阈值
- 常见的限流有<br>
  限制总并发数（比如数据库连接池、线程池）<br>
  限制瞬时并发数（如Nginx的limit_conn模块）<br>
  限制时间窗口内的平均速率（如Guava的RateLimiter、Nginx的limit_req模块，用来限制每秒的平均速率）<br>
  限制远程接口调用速率<br>
  限制MQ的消费速率<br>
  还可以根据网络连接数、网络流量、CPU或内存负载来限流<br>
- 缓存目的是提升系统访问速度和增大系统处理能力，可谓是抗高并发的银弹。降级是当服务出问题或者影响到核心流程的性能，需要暂时屏蔽掉，待高峰过去或者问题解决后再打开的场景<br>
  A.限流算法<br>
  1.令牌桶算法：是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌<br>
  2.漏桶算法：漏桶作为计量工具（The Leaky Bucket Algorithm as a Meter）时，可以用于流量整形（Traffic Shaping）和流量控制（Traffic Policing）<br>
  B.应用级限流<br>
  1.限流总资源数：可以使用池化技术，如连接池、线程池<br>
  2.限流总并发/连接/请求数：Tomcat配置、MySQL（max_connections）、Redis（tcp-backlog）<br>
  3.限流某个接口的总并发/请求数：Java的AtomicLong或Semaphore<br>
  C.分布式限流<br>
  1.Redis+Lua<br>
  2.Nginx+Lua<br>
  D.接入层限流<br>
  1.接入层通常指请求流量的入口，该层的主要目的有：负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等<br>
  2.ngx_http_limit_conn_module，limit_conn是对某个key对应的总的网络连接数进行限流，可以按照IP来限制IP维度的总连接数，或者按照服务域名来限制某个域名的总连接数，只有被Nginx处理的且已经读取了整个请求头的请求连接才会被计数器统计<br>
  3.ngx_http_limit_req_module，limit_req是漏桶算法实现，用于对指定key对应的请求进行限流，比如按照IP维度限制请求速率<br>
  4.lua-resty-limit-traffic，OpenResty了Lua限流模块，可以按照更复杂的业务逻辑进行动态限流处理，提供了limit.conn和limit.req实现<br>
  E.节流<br>
  1.我们想在特定埋单窗口内对重复的相同事件最多只处理一次，或者想限制多个连续相同事件最小执行时间间隔，可使用节流（Throttle）实现，其防止多个相同事件连续重复执行，主要有：throttleFirst、throttleLast、throttleWithTimeout<br>
  2.throttleFirst/throttleLast<br>
是指在一个时间窗口内，如果有重复的多个相同事件要处理，则只处理第一个或最后一个，其相当于一个事件频率控制器，把一段时间内重复的多个相同事件变为一个，减少事件处理频频率，从而减少无用处理
前端开发可以使用jquery-throttle-debounce-plugin实现，Android开发可以使用RxAndroid实现<br>
  3.throttleWithTimeout<br>
也叫作debounce（去抖），限制两个连续事件的先后执行时间不得小于某个时间窗口<br>
当两个连续事件的时间间隔小于最小间隔时间窗口，就会丢弃上一个事件，而如果最后一个事件等待了最小间隔时间窗口后还没有新的事件到来，那么会处理最后一个事件，可用于搜索关键词自动补全等功能
### 4、降级
- 当访问量剧增、服务出现问题（如响应时间长或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级
- 降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如购物车、结算）。降级也需要根据系统的吞吐量、响应时间、可用率等条件进行手工降级或自动降级<br>
  A.降级预案<br>
  1.参考日志级别设置预案<br>
一般：有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级<br>
警告：有些服务在一段时间内成功率有波动，可以自动降级或人工降级并发送警告<br>
错误：可用率低于90%，或数据库连接池用完了，或访问量突然猛增到系统能承受的最大阈值<br>
严重错误：因为特殊原因数据出现错误，需要紧急人工降级<br>
  2.降级按照是否自动化可分为：自动开关降级和人工开关降级<br>
  3.降级按照功能可分为：读服务降级和写服务降级<br>
  4.降级按照处于系统层次可分为：多级降级<br>
  5.降级的功能点主要从服务器端链路考虑，即根据用户访问的服务调用链路来梳理哪里需要降级：页面降级，页面片段降级，页面异步请求降级，服务功能降级<br>
读降级：如多级缓存模式，如果后端服务有问题，则可以降级为只读缓存，适用于对读一致性要求不高的场景<br>
写降级：秒杀抢购，可以只进行Cache的更新，然后异步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache<br>
爬虫降级：大促活动时，可以将爬虫流量导向静态页或者返回空数据，从而保护后端稀缺资源<br>
风控降级：抢购/秒杀等业务，完全可以识别机器人、用户画像或者根据用户风控级别进行降级处理，直接拒绝高风险用户<br>
  B.自动开关降级<br>
  1.超时降级<br>
当访问的数据库/HTTP服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话，可以在超时后自动降级<br>
如果是调用别人的远程服务，则可以和对方定义一个服务响应最大时间，如果超时了，则自动降级<br>
在实际场景中一定要配置好超时时间和超时重试次数及机制<br>
  2.统计失败次数降级：当失败调用次数达到一定阈值自动降级（熔断器），然后通过异步线程去探测服务是否恢复了<br>
  3.故障降级：要调用的远程服务挂掉了，则可以直接降级，降级后的处理方案：默认值（比如库存挂了返回默认） 、兜底数据（比如广告挂了返回提前准备好的静态页面）、缓存<br>
  4.限流降级：当达到限流阈值时，后续请求会被降级，降级后的处理方案：排队页面、无货、错误页<br>
  C.人工开关降级<br>
  1.开关可以存放到配置文件、数据库、Redis/ZooKeeper，可以定期同步开关数据，然后通过判断某个KEY的值来决定是否降级<br>
  2.对于新开发的服务进行灰度测试，就需要设置开关，还有多机房服务，也可以通过开关完成<br>
  3.还有一引起是因为功能问题需要暂时屏蔽掉某些功能<br>
  D.读服务降级<br>
  1.一般采取的策略有：暂时切换读（降级到读缓存、降级走静态化）、暂时屏蔽读（屏蔽读入口、屏蔽某个读服务）<br>
  2.我们会在接入层、应用层设置开关，当分布式缓存、RPC服务/DB有问题时自动降级为不调用，适用于读一致性要求不高的场景<br>
  3.页面降级、页面片段降级、页面异步请求降级都是读服务降级，目的是丢卒保帅<br>
  4.动态化降级为静态化<br>
  5.静态化降级为动态化<br>
  E.写服务降级<br>
  1.大多数场景下是不可降级的，不过可以：将同步操作转换为异步操作、限制写的量/比例（如评论开关量大时不可见）<br>
  F.多级降级<br>
  1.降级是离用户走越近越对系统保护得好，因为业务的复杂性导致越到后端QPS/TPS越低<br>
页面JS降级开关：控制页面功能降级<br>
接入层降级开关：控制请求入口的降级<br>
应用层降级开关：控制业务的降级<br>
  G.配置中心<br>
  1.应用层API封装<br>
  2.使用配置文件实现开关配置<br>
  3.使用配置中心实现开关配置：ZooKeeper、Diamond、Disconf、Etcd3、Consul<br>
  H.使用Hystrix实现降级<br>
  I.使用Hystrix实现熔断<br>
### 5、超时与重试Ribbon
- A.简介<br>
  1.如果应用不设置超时，则可能会导致请求响应慢，慢请求累积导致连锁反应，甚至造成应用雪崩<br>
  2.读服务天然适合重试，而写服务大多不能重试（如果写服务是幂等的，则重试是允许的），重试次数太多会导致多倍请求流量<br>
  3.在进行代码Review时，一定记得Review超时与重试机制<br>
  4.超时与重试机制：代理层超时与重试，Web容器超时，中间件客户端超时与重试，数据库客户端超时，NoSQL客户端超时，业务超时，前端Ajax超时
- B.代理层超时与重试
  1.Nginx<br>
  client_header_timeout time：设置读取客户端请求头超时时间，默认为60s，响应408，如果在些超时时间内客户端没有发送完请求头<br>
  client_body_timeout time：设置读取客户端内容体超时时间，默认为60s，响应408，两次成功读操作间隔时间，而不是发送整个请求体超时时间<br>
  send_timeout_time：设置发送响应到客户端的超时时间，默认60s，两次成功写操作间隔时间，而不是发送整个响应的超时时间<br>
  keepalive_timeout timeout [header_timeout]：设置HTTP长连接超时时间，要配合keepalive_disable和keepalive_requests一起使用<br>
  2.DNS解析超时设置<br>
  resolver_timeout 30s：设置DNS解析超时时间，默认30s，配合resolver address ... [valid=time]进行DNS域名解析<br>
  3.代理超时设置<br>
  proxy_connect_timeout time：与后端/上游服务器建立连接的超时时间<br>
  proxy_read_timeout time：设置从后端/上游服务器读取响应的超时时间<br>
  proxy_send_timeout time：设置往后端/上游服务器发送请求的超时时间<br>
  proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | non_idempotent | off ...：配置什么情况下需要请求下一台上游服务器进行重试ZXCV<br>
  proxy_next_upstream_tries number：设置重试次数，指所有请求次数，默认0表示不限制<br>
  proxy_next_upstream_timeout time：设置重试最大超时时间，默认0表示不限制<br>
  upstream存活超时，max_fails和fail_timeout：配置什么时候Nginx将上游服务器认定为不可用/不存活<br>
  4.Twemproxy：Twitter开源的Redis和Memcache代理中间件，减少与后端缓存服务器的连接数<br>
- C.Web容器超时
- D.中间件客户端超时与重试<br>
  1.JSF是京东自研的SOA框架，主要有三个组件：注册中心、服务提供端、服务消费端<br>
  2.JMQ是京东消息中间件，主要有四个组件：注册中心、Broker（JMQ的服务器端实例，生产和消费消息都跟它交互）、生产者、消费者
- E.数据库客户端超时
- F.NoSQL客户端超时
- G.业务超时<br>
  1.任务型：可以通过Worker定期扫描数据库修改状态，有时需要远程服务超时了，可以考虑使用队列或者暂时记录到本地稍后重试<br>
  2.服务调用型：可以简单地使用Futrue来解决问题（Java）
- H.前端Ajax超时<br>
  1.可以在请求时带上timeout参数<br>
  2.使用setTimeout进行超时重试
### 6、回滚
- A.事务回滚<br>
  1.对于单库事务回滚直接使用相关SQL即可<br>
  2.分布式事务常见的如两阶段提交、三阶段提交协议，可以考虑事务表、消息队列、补偿机制（执行/回滚）、TCC模式（预占/确认/取消）、Sagas模式（拆分事务+补偿机制）等实现最终一致性
- B.代码库回滚<br>
  1.SVN、Git等
- C.部署版本回滚<br>
  1.部署版本化：发布时采用全量发布，避免增量发布<br>
  2.小版本增量发布：先发布1台验证，没问题发布10台，最后全部发布<br>
  3.大版本灰度发布：两个版本并行跑一段时间<br>
  4.架构升级并发发布：通过A/B方式慢慢地将流量引入到新版本集群，如果新版本出现大面积故障，降级回老版本
- D.数据版本回滚<br>
  1.两种思路：全量和增量<br>
全量版本化是指即使只变更了其中一个字段也将整体记录进行历史版本化<br>
增量版本化是只保存变化的字段
### 7、压测预案
- A.系统压测<br>
  1.压测一般指性能压力测试，用来评估系统的稳定性和性能，从而决定是否需要扩容或缩容<br>
  2.压测之前要有压测方案【如压测接口、并发量、压测策略（突发、逐步加压、并发量）、压测指标（机器）】，之后要产出压测报告【压测方案、机器负载、QPS/TPS、响应时间（平均、最小、最大）、成功率、相关参数（JVM参数、压缩参数）】，最后根据压测报告分析的结果进行系统优化和容灾<br>
  3.线下压测：通过如JMeter、Apache ab压测系统的某个接口或者某个组件<br>
  4.线上压测：按读写分为读压测、写压测和混合压测，按数据仿真度分为仿真压测和引流压测，按是否给用户提供服务分为隔离集群压测和线上集群压测<br>
  5.读压测是压测系统的读流量，写压测是辱没系统的写流量，读和写是会相互影响 的，因此，这种情况下要进行混合压测<br>
  6.仿真压测是通过模拟请求进行系统压测，数据可以是使用程序构造、人工构造，或者使用Nginx访问日志<br>
  7.隔离集群压测是指将对外提供服务的部分服务器从线上集群摘除，然后将线上流量引流到该集群进行压测，这种方式很安全<br>
  8.单机压测是指对集群中的一台机器进行压测，从而评估出单机极限处理能力，发现单机的瓶颈点，这样可以把单机性能优化到极致<br>
  9.离散压测，即选择的数据应该是分散的或者长尾的<br>
  10.全链路压测<br>
- B.系统优化和容灾<br>
  1.拿到压测报告 后，接下来会分析报告，然后进行一些有针对性的优化，如硬件升级、系统扩容、参数调优、代码优化、架构优化<br>
  2.在进行系统优化时，要进行代码走查，发现不合理的参数配置，如超时时间、降级策略、缓存时间等，在系统压测中进行慢查询排查，包括Redis、MySQL等，通过优化查询解决慢查询问题<br>
  3.在应用系统扩容方面，可以根据去年流量、与运营业务方沟通促销力度、最近一段时间的流量来评估出是否需要进行扩容，需要扩容多少倍<br>
  4.在扩容时要考虑系统容灾，比如分组部署、跨机房部署，容灾是通过部署多组（单机房/多机房）相同应用系统，当其中一组出现问题时，可以切换到另一个分组
- C.应急预案<br>
  1.系统分级：可以按照交易核心系统和交易支撑系统进行划分<br>
  2.针对核心系统进行全链路分析，从用户入口到后端存储，梳理出各个关键路径，对相关路径进行评估并制定预案<br>
网络接入层：由系统工程师负责，关注机房不可用、DNS故障、VIP故障等预案处理<br>
应用接入层：由开发工程师负责，关注上游应用路由切换、限流、降级、隔离等预案处理<br>
Web应用层和服务层：由开发工程师负责，关注依赖服务的路由切换、连接池（数据库、线程池等）异常、限流、超时降级、服务异常降级、应用负载异常、数据库故障切换、缓存故障切换等<br>
数据层：由开发工程师或系统工程师负责，关注数据库/缓存负载高、数据库/缓存故障等<br>
  3.制定好预案后，应对预案进行演习，来验证预案的正确性，在制定预案时也要设定故障的恢复时间<br>
  4.要对关联路径实施监控报警，包括服务器监控（CPU使用率、磁盘使用每户、网络带宽等）、系统监控（系统存活、URL状态/内容监控、端口存活等）、JVM监控（堆内存、GC次数、线程数等）、接口监控【接口调用量（每秒/每分钟）、接口性能（TOP50/TOP99/TOP999）、接口可用率等】，然后配置报警策略如监控时间段、报警阈值、通知方式
### 二、高并发
### 1、缓存
- 应用级缓存<br>
1、缓存回收策略<br>
基于空间、基于容量、基于时间（TTL、TTI）、基于Java对象引用（软引用、弱引用）、基于会是算法（FIFO、LRU（Leas Recently Used）、LFU（Lease Frequently Used））<br>
2、Java缓存类型<br>
堆缓存（最快，没有序列化/反序列化，但GC暂停时间会变长）（Guava Cache、Ehcache 3.x、MapDB）<br>
堆外缓存（比堆缓存慢，需要序列化/反序列化，可以减少GC暂停时间）（Ehcache 3.x、MapDB）<br>
磁盘缓存（Ehcache 3.x、MapDB）<br>
分布式缓存（Redis、Memcached）<br>
3、缓存使用模式<br>
Cache-Aside，即业务代码围绕着Cache写，是由业务代码直接维护缓存。Cache-Aside适合使用AOP模式去实现。<br>
Cache-AS-SoR（system of record，或者可以叫数据源），所有的操作都是对Cache进行，然后再委托给SoR进行真实的读/写。即业务代码中只看到Cache的操作，看不到关于SoR相关的代码。<br>
4、Cache-AS-SoR共有三种实现方式<br>
Read-Through，业务代码首先调用Cache，如果Cache不命中，由Cache回源到SoR，而不是业务代码（即由Cache读SoR）。Guava Cache和Ehcache 3.x都支持该模式。<br>
Write-Through，被称为穿透写模式/直写模式。业务代码首先调用Cache写（新增/修改）数据，然后由Cache负责写缓存和写SoR，而不是业务代码。Ehcache 3.x支持。<br>
Write-Behind，也叫Write-Back，我们称之为回写模式。不同于Write-Through是同步写SoR和Cache，Write-Behind是异步写。异步之后可以实现批量写、合并写、延时和限流。
- HTTP缓存<br>
1、HTTP缓存<br>
服务端响应的Last-Modified会在下次请求时，将If-Modified-Since请求头带到服务器端进行文档是否修改的验证，如果没有修改则返回304，浏览器可以直接使用缓存内容<br>
Cache-Control:max-age和Expires用于决定浏览器端内容缓存多久，即多久过期，过期后则删除缓存重新从服务器端获取最新的。另外，可以用于from cache场景。<br>
HTTP/1.1规范定义ETag为“被请求变量的实体值”，可简单理解为文档内容摘要，ETag可用来判断页面内容是否已经被修改了。<br>
2、HttpClient客户端缓存、Nginx配置、Nginx代理层缓存
- 多级缓存<br>
多级缓存，是指在整个系统架构的不同系统层级进行数据缓存，以提升访问效率，这是应用最广的方案之一。<br>
1、维度华缓存与增量缓存、大Value缓存处理、热点缓存处理<br>
2、缓存分布式及应用负责均衡算法选择<br>
负载较低时，使用一致性哈希。热点请求降级一致性哈希为轮询，或者如果请求数据有规律，则可考虑带权重的一致性哈希。将热点数据推送到接入层Nginx，直接响应给用户。<br>
3、热点数据：热点数据会造成服务器压力过大，导致服务器性能、吞吐量、带宽达到极限，出现响应慢或者拒绝服务的情况，这肯定是不允许的。<br>
4、单机全量缓存+主从（热点数据解决方案1）：一般不采用，针对缓存量比较大的应用不适用。<br>
5、分布式缓存+应用本地热点（热点数据解决方案2）<br>
①接入Nginx将请求转发给应用Nginx。（这种更适合应用层面的，对于服务内部的缓存，还可以采用Guava cache等本地的堆内缓存、堆外缓存等。）<br>
②应用Nginx首先读取本地缓存。如果命中，则直接返回，不命中会读取分布式缓存、回源到Tomcat进行处理。<br>
③应用Nginx会将请求上报给实时热点发现系统，上报给实时热点发现系统后，它将进行热点统计。<br>
④根据设置的阈值将热点数据推送到应用Nginx本地缓存。<br>
6、缓存数据一致性<br>
订阅数据变更消息，如果无法订阅消息或者订阅消息成本比较高，并且对短暂的数据一致性要求不严格（比如，在商品详情页看到的库存，可以短暂的不一致，只要保证下单时一致即可），那么可以设置合理的过期时间，过期后再查询新的数据。
如果是秒杀之类的（热点数据），可以订阅活动开启消息，将相关数据提前推送到前端应用，并将负载均衡机制降级为轮询。建立实时热点发现系统来对热点进行统一推送和更新<br>
7、缓存崩溃恢复<br>
主从机制，做好冗余，即其中一部分不可用，将对等的部分补上去。如果因为缓存导致应用可用性已经下降，可以考虑部分用户降级，然后慢慢减少降级量，后台通过Worker预热缓存数据。
### 2、连接池线程池
- 池化技术<br>
在应用系统开发中，我们经常会用到池化技术，如对象池、连接池、线程池等，通过池化来减少一些消耗，以提升性能。对象池通过复用对象从而减少创建对象、垃圾回收的开销，但是池不能太大，太大会影响GC时的扫描时间。连接池如数据库连接池、Redis连接池、HTTP连接池，通过复用TCP连接来减少创建和释放连接的时间来提升性能。线程池也是类似的，通过复用线程提升性能。也就是说池化的目的是通过复用技术提升性能。
- 连接池Druid使用的建议<br>
注意网络阻塞/不稳定时的级联效应，连接池内部应该根据当前网络的状态（比如超时次数太多），对于一定时间内的（如100ms）全部timeout，根本不进行await（maxWait），即有熔断和快速失败机制。<br>
当前等待连接池的数目超过一定量时，接下来的等待是没有意义的，还会造成滚雪球效应<br>
等待超时应尽可能小点（除非很必要）。即使返回错误页，也比等待并阻塞强。
- 线程池Async<br>
更多的Java TreadExecutors相关的内容。相关配置项如：核心线程池大小、线程池最大大小、线程的最大空闲时间（超过则回收，直到线程数减为核心线程大小）、线程池的任务缓冲队列、创建线程的工厂、缓冲队列满后的拒绝策略等。另外还有支持延时任务的线程池。
- 线程池使用的建议<br>
根据任务类型是IO密集型还是CPU密集型、CPU核数，来设置合理的线程池大小、队列大小、拒绝策略，并进行压测和调优来决定适合场景的参数。<br>
使用线程池时务必设置池大小、队列大小并设置相应的拒绝策略。不设可能导致瞬间线程数过高、GC慢等问题，造成系统响应慢。
### 3、异步并发
- 异步与并发<br>
当一个线程在处理任务时，通过Fork多个线程来处理任务并等待这些线程的处理结果，这种并不是真正的异步，这只是并发。异步是针对CPU和IO的，当IO没有就绪时，要让出CPU来处理其他任务，这才是异步。
- 异步Future<br>
线程池配合Future实现，但是阻塞主请求流程，高并发时依然会造成线程数过多、CPU上下文切换。
- 异步Callback<br>
通过回调机制实现，即首先发出网络请求，当网络返回时回调相关方法，采用线程池分发事件通知，从而有效支撑大量并发连接。这种机制并不能提升性能，而是为了支撑大量并发连接或者提升吞吐量。
- 异步编排CompletableFuture<br>
JDK 8 CompletableFuture提供了新的异步编程思路，可以对多个异步处理进行编排，实现更复杂的异步处理，其内部使用了ForkJoinPool实现异步处理。比如三个服务异步并发调用、两个服务并发调用、服务1执行完后再并发执行服务2服务3等场景。
- 异步Web服务实现
- 请求缓存
- 请求合并
### 4、扩容
- 跨库事务<br>
当然分布式事务是一种方式，另一种方式可以考虑sharding-jdbc提供的柔性事务实现。目前支持最大努力送达，就是当事务失败后通过最大努力反复尝试，是在假定数据库操作一定可以成功的前提下进行的，保证数据最终的一致性。其使用场景是幂等性操作，如根据主键删除数据、带主键插入数据。
- 柔性事务<br>
sharding-jdbc的最大努力送达型柔性事务分为同步送达和异步送达两种，同步送达不需要Zookeeper和elastic-job，内置在柔性事务模块中。异步送达比较复杂，是对柔性事务的最终补充，不能和应用程序部署在一起，需要额外地通过elastic-job实现。最大努力送达型事务也可能出现错误，即无论如何补充都不能正确提交。为了避免反复尝试带来的系统开销，同步送达和异步送达均可配置最大重试次数，超过最大重试次数的事务将进入失败列表。
- 数据异构<br>
查询维度异构、聚合据异构
- 分布式任务<br>
Quartz支持任务的集群调度，如果一个实例失效，则可以漂移到其他实例进行处理，但是其不支持任务分片。tbschedule和elastic-job除了支持集群调度特性，还不支持任务分片，从而可以进行动态扩容/缩容
- Elastic-Job
Elastic-Job是当当开源的一款分布式任务调度框架，目前提供了两个独立子项目：Elastic-Job-Lite和Elastic-Job-Cloud。Elastic-Job-Lite定位为轻量级无中心解决方案，可以动态暂停/恢复任务实例，目前不支持动态扩容任务实例。Elastic-Job-Cloud使用Mesos+Docker解决方案，可以根据任务负载来动态实现启动/停止任务实例，以及任务治理。
- Elastic-Job-Lite功能与架构<br>
Elastic-Job-Lite实现了分布式任务调度、动态扩容缩容、任务分片、失效转移、运维平台等功能。<br>
Elastic-Job-Lite采用去中心化的调度方案，由Elastic-Job-Lite的客户端定时自动触发任务调度，通过任务分片的概念实现服务器负载的动态扩容/缩容，并且使用Zookeeper作为分布式任务调度的注册和协调中心，当某任务实例崩溃后，自动失效转移，实现高可用，并提供了运维控制台，实现任务参数的动态修改。
### 5、队列
- 使用队列注意点<br>
要考虑是否需要保证消息处理的有序性及如何保证，是否能重复消费及如何保证重复消费的幂等性。
- 队列应用场景<br>
异步处理、系统解耦、数据同步、流量削锋、扩展性、缓冲等。
- 缓冲队列<br>
比如Log4j日志缓冲区就是使用的缓冲队列。使用缓冲队列应对突发流量时，并不能使处理速度变快，而是使处理速度平滑，从而不因瞬间压力太大而压垮应用。通过缓冲区队列可以实现批量处理、异步处理和平滑流量。
- 任务队列<br>
使用任务队列可以将一些不需要与主线程同步执行的任务扔到任务队列进行异步处理。可以实现异步处理、任务分解/聚合处理。
- 消息队列<br>
通过消息队列可以实现异步处理、系统解耦和数据异构。
- 请求队列<br>
类似在Web环境下对用户请求排队，从而进行一些特殊控制：流量控制、请求分级、请求隔离。例如将请求按照功能划分不同的队列，从而使得不同的队列出问题后相互不影响。还可以对请求分级，一些重要的请求可以优先处理（发展到一定程度应将功能物理分离）。
- 数据总线队列
- 混合队列<br>
如MQ与Redis的协同组合使用。Disruptor+Redis队列
- 基于Canal实现数据异构<br>
在大型网站架构中，一般会采用分库分表来解决容量和性能问题。但分库分表后，不同维度的查询或者聚合查询就会非常棘手，而且这种方式在大流量系统架构中肯定是不行的。一种解决方式就是数据异构，可以包含具体场景接口的异构、商家维度的异构、ES搜索异构、订单缓存异构等。
